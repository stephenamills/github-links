DAIR
https://github.com/dair-ai/prompt-engineering-guide # üêô Guides, papers, lecture, notebooks and resources for prompt engineering
https://github.com/dair-ai/ml-visuals # üé® ML Visuals contains figures and templates which you can reuse and customize to improve your scientific writing.
https://github.com/dair-ai/ml-papers-explained # Explanation to key concepts in ML
https://github.com/dair-ai/mathematics-for-ml # üßÆ A collection of resources to learn mathematics for machine learning
https://github.com/dair-ai/ml-notebooks # :fire: Machine Learning Notebooks
https://github.com/dair-ai/transformers-recipe # üß† A study guide to learn about Transformers
https://github.com/dair-ai/nlp_paper_summaries # ‚úçÔ∏è A carefully curated list of NLP paper summaries
https://github.com/dair-ai/mlops-primer # A collection of resources to learn about MLOps.
https://github.com/dair-ai/d2l-study-group # üß† Material for the Deep Learning Study Group
https://github.com/dair-ai/nlp_fundamentals # üìò Contains a series of hands-on notebooks for learning the fundamentals of NLP
https://github.com/dair-ai/notebooks # üî¨ Sharing your data science notebooks with the community has never been this easy.
https://github.com/dair-ai/covid_19_search_application # Text Similarity Search Application using Modern NLP and Elasticsearch
https://github.com/dair-ai/odsc_2020_nlp # Repository for ODSC talk related to Deep Learning NLP
https://github.com/dair-ai/data_science_writing_primer # Writing Primer for Data Scientists
https://github.com/dair-ai/llm-evaluator # Example for Logging LLM Evaluator Prompt Responses
https://github.com/dair-ai/pe-for-llms #
https://github.com/dair-ai/paper_implementations # A project for implementing ML and NLP papers
https://github.com/dair-ai/paper_presentations # All paper presentation material will be added here
https://github.com/dair-ai/datasets # AI Datasets
https://github.com/dair-ai/deep_affective_layer # :smile: Building a deep learning based affective computing platform
https://github.com/dair-ai/.github #

EleutherAI
https://github.com/eleutherai/gpt-neox # An implementation of model parallel autoregressive transformers on GPUs, based on the Megatron and DeepSpeed libraries
https://github.com/eleutherai/lm-evaluation-harness # A framework for few-shot evaluation of language models.
https://github.com/eleutherai/pythia # The hub for EleutherAI's work on interpretability and learning dynamics
https://github.com/eleutherai/the-pile #
https://github.com/eleutherai/math-lm #
https://github.com/eleutherai/cookbook # Deep learning for dummies. All the practical details and useful utilities that go into working with real models.
https://github.com/eleutherai/polyglot # Polyglot: Large Language Models of Well-balanced Competence in Multi-languages
https://github.com/eleutherai/dalle-mtf # Open-AI's DALL-E for large scale training in mesh-tensorflow.
https://github.com/eleutherai/vqgan-clip #
https://github.com/eleutherai/sae # Sparse autoencoders
https://github.com/eleutherai/concept-erasure # Erasing concepts from neural representations with provable guarantees
https://github.com/eleutherai/elk # Keeping language models honest by directly eliciting knowledge encoded in their activations.
https://github.com/eleutherai/oslo # OSLO: Open Source for Large-scale Optimization
https://github.com/eleutherai/lm_perplexity #
https://github.com/eleutherai/knowledge-neurons # A library for finding knowledge neurons in pretrained transformer models.
https://github.com/eleutherai/pyfra # Python Research Framework
https://github.com/eleutherai/dps # Data processing system for polyglot
https://github.com/eleutherai/openwebtext2 #
https://github.com/eleutherai/improved-t5 # Experiments for efforts to train a new and improved t5
https://github.com/eleutherai/stackexchange-dataset # Python tools for processing the stackexchange data dumps into a text dataset for Language Models
https://github.com/eleutherai/project-menu # See the issue board for the current status of active and prospective projects!
https://github.com/eleutherai/sae-auto-interp #
https://github.com/eleutherai/magicarp # One stop shop for all things carp
https://github.com/eleutherai/semantic-memorization #
https://github.com/eleutherai/tqdm-multiprocess # Using queues, tqdm-multiprocess supports multiple worker processes, each with multiple tqdm progress bars, displaying them cleanly through the main process. 
https://github.com/eleutherai/aria #
https://github.com/eleutherai/hae-rae #
https://github.com/eleutherai/rnngineering # Engineering the state of RNN language models (Mamba, RWKV, etc.)
https://github.com/eleutherai/features-across-time # Understanding how features learned by neural networks evolve throughout training
https://github.com/eleutherai/mp_nerf # Massively-Parallel Natural Extension of Reference Frame
https://github.com/eleutherai/elk-generalization # Investigating the generalization behavior of LM probes trained to predict truth labels: (1) from one annotator to another, and (2) from easy questions to hard
https://github.com/eleutherai/pile-pubmedcentral # A script for collecting the PubMed Central dataset in a language modelling friendly format.
https://github.com/eleutherai/aria-amt # Efficient and robust implementation of seq-to-seq automatic piano transcription.
https://github.com/eleutherai/polyglot-data # data related codebase for polyglot project
https://github.com/eleutherai/best-download # URL downloader supporting checkpointing and continuous checksumming.
https://github.com/eleutherai/text-generation-testing-ui # Web app for demoing the EAI models
https://github.com/eleutherai/exploring-contrastive-topology #
https://github.com/eleutherai/mdl # Minimum Description Length probing for neural network representations
https://github.com/eleutherai/w2s #
https://github.com/eleutherai/tokengrams # Efficiently computing & storing token n-grams from large corpora
https://github.com/eleutherai/pile_dedupe # Pile Deduplication Code
https://github.com/eleutherai/pilev2 #
https://github.com/eleutherai/equivariance # A framework for implementing equivariant DL
https://github.com/eleutherai/radioactive-lab # Adapting the "Radioactive Data" paper to work for text models
https://github.com/eleutherai/tagged-pile # Part-of-Speech Tagging for the Pile and RedPajama
https://github.com/eleutherai/pile-literotica # Download, parse, and filter data from Literotica. Data-ready for The-Pile.
https://github.com/eleutherai/hn-scraper #
https://github.com/eleutherai/multimodal-fid #
https://github.com/eleutherai/pile-uspto # A script for collecting the USPTO Backgrounds dataset in a language modelling friendly format.
https://github.com/eleutherai/pile-cc-filtering # The code used to filter CC data for The Pile
https://github.com/eleutherai/codecarp # Data collection pipeline for CodeCARP. Includes PyCharm plugins.
https://github.com/eleutherai/minetest-baselines # Baseline agents for Minetest tasks.
https://github.com/eleutherai/pile-enron-emails # A script for collecting the Enron Emails dataset in a language modelling friendly format.
https://github.com/eleutherai/llemma-sample-explorer # Sample explorer tool for the Llemma models.
https://github.com/eleutherai/eleutherai.github.io # This is the Hugo generated website for eleuther.ai. The source of this build is new-website repo.
https://github.com/eleutherai/minetest-interpretabilty-notebook # Jupyter notebook for the interpretablity section of the minetester blog post
https://github.com/eleutherai/llm-markov-chains # Project github for LLM Markov Chains Project
https://github.com/eleutherai/visual-grounding # Visually ground GPT-Neo 1.3b and 2.7b
https://github.com/eleutherai/thonkenizers # yes
https://github.com/eleutherai/architecture-experiments # Repository to host architecture experiments and development using Paxml and Praxis
https://github.com/eleutherai/pile-explorer # For exploring the data and documenting its limitations
https://github.com/eleutherai/ccs #
https://github.com/eleutherai/unpaired-image-generation # Project Repo for Unpaired Image Generation project
https://github.com/eleutherai/lm-scope #
https://github.com/eleutherai/website # New website for EleutherAI based on Hugo static site generator
https://github.com/eleutherai/latent-video-diffusion # Latent video diffusion
https://github.com/eleutherai/equinox-llama # Equinox implementation of llama3 and llama3.1
https://github.com/eleutherai/pile-allpoetry # Scraper to gather poems from allpoetry.com
https://github.com/eleutherai/pile-ubuntu-irc # A script for collecting the Ubuntu IRC dataset in a language modelling friendly format.
https://github.com/eleutherai/evilmodel # A replication of "EvilModel 2.0: Bringing Neural Network Models into Malware Attacks"
https://github.com/eleutherai/isaac-mchorse # EleutherAI's discord bot
https://github.com/eleutherai/optax-galore # Adds GaLore style projection wrappers to optax optimizers
https://github.com/eleutherai/variance-across-time # Studying the variance in neural net predictions across training time
https://github.com/eleutherai/eai-prompt-gallery # Library of interesting prompt generations
https://github.com/eleutherai/eleutherai-instruct-dataset # A large instruct dataset for open-source models (WIP).
https://github.com/eleutherai/bucket-cleaner # A small utility to clear out old model checkpoints in Google Cloud Buckets whilst keeping tensorboard event files
https://github.com/eleutherai/reddit-comment-processing #
https://github.com/eleutherai/steering-llama3 #
https://github.com/eleutherai/groupoid-rl #
https://github.com/eleutherai/lang-filter # Filter text files or archives by language
https://github.com/eleutherai/eleuther-blog # here is the generated content for the EleutherAI blog. Source is from new-website repo
https://github.com/eleutherai/conceptual-constraints # Applying LEACE to models during training
https://github.com/eleutherai/bayesian-adam # Exactly what it says on the tin
https://github.com/eleutherai/common-llm-settings # Common LLM Settings App
https://github.com/eleutherai/prefix-free-tokenizer # A prefix free tokenizer
https://github.com/eleutherai/pd-books #
https://github.com/eleutherai/pile-cord19 # A script for collecting the CORD-19 dataset in a language modelling friendly format.
https://github.com/eleutherai/grouch #
https://github.com/eleutherai/alignment-reader # Search and filter through alignment literature
https://github.com/eleutherai/ngrams-across-time #
https://github.com/eleutherai/language-adaptation #
https://github.com/eleutherai/visual-grounding-jax # Experiments pertaining to visually grounding Neo, built off of mesh-transformer-jax
https://github.com/eleutherai/openinstructdata #
https://github.com/eleutherai/aria.cpp # GGML implementation of https://github.com/EleutherAI/aria
https://github.com/eleutherai/omnitrack # Unified Experiment Tracking.
https://github.com/eleutherai/depoison # Fixes poisoned directories in google cloud buckets
https://github.com/eleutherai/llm-score-behavior #
https://github.com/eleutherai/pile-arxiv #
https://github.com/eleutherai/lm-evaulation-ui # App for generating html table from LM evaluation JSONs
https://github.com/eleutherai/sgdensity # Computing the implicit probability densities that SGD assigns to networks
https://github.com/eleutherai/classifier-latent-diffusion #
https://github.com/eleutherai/poll_website_demo # Flask Based Polling Website Demo

Hugging Face
https://github.com/huggingface/transformers # ü§ó Transformers: State-of-the-art Machine Learning for Pytorch, TensorFlow, and JAX.
https://github.com/huggingface/pytorch-image-models # The largest collection of PyTorch image encoders / backbones. Including train, eval, inference, export scripts, and pretrained weights -- ResNet, ResNeXT, EfficientNet, NFNet, Vision Transformer (ViT), MobileNetV4, MobileNet-V3 & V2, RegNet, DPN, CSPNet, Swin Transformer, MaxViT, CoAtNet, ConvNeXt, and more
https://github.com/huggingface/diffusers # ü§ó Diffusers: State-of-the-art diffusion models for image and audio generation in PyTorch and FLAX.
https://github.com/huggingface/datasets # ü§ó The largest hub of ready-to-use datasets for ML models with fast, easy-to-use and efficient data manipulation tools
https://github.com/huggingface/peft # ü§ó PEFT: State-of-the-art Parameter-Efficient Fine-Tuning.
https://github.com/huggingface/candle # Minimalist ML framework for Rust
https://github.com/huggingface/trl # Train transformer language models with reinforcement learning.
https://github.com/huggingface/tokenizers # üí• Fast State-of-the-Art Tokenizers optimized for Research and Production
https://github.com/huggingface/text-generation-inference # Large Language Model Text Generation Inference
https://github.com/huggingface/accelerate # üöÄ Train, and use PyTorch models on almost any device and distributed configuration, automatic mixed precision (including fp8), and easy-to-configure FSDP and DeepSpeed support
https://github.com/huggingface/chat-ui # Open source codebase powering the HuggingChat app
https://github.com/huggingface/lerobot # ü§ó LeRobot: Making AI for Robotics more accessible with end-to-end learning
https://github.com/huggingface/alignment-handbook # Robust recipes to align language models with human and AI preferences
https://github.com/huggingface/parler-tts # Inference and training library for high-quality TTS models.
https://github.com/huggingface/deep-rl-class # This repo contains the syllabus of the Hugging Face Deep Reinforcement Learning Course.
https://github.com/huggingface/autotrain-advanced # ü§ó AutoTrain Advanced
https://github.com/huggingface/notebooks # Notebooks using the Hugging Face libraries ü§ó
https://github.com/huggingface/diffusion-models-class # Materials for the Hugging Face Diffusion Models Course
https://github.com/huggingface/distil-whisper # Distilled variant of Whisper for speech recognition. 6x faster, 50% smaller, within 1% word error rate.
https://github.com/huggingface/speech-to-speech # Speech To Speech: an effort for an open-sourced and modular GPT4-o
https://github.com/huggingface/neuralcoref # ‚ú®Fast Coreference Resolution in spaCy with Neural Networks
https://github.com/huggingface/knockknock # üö™‚úäKnock Knock: Get notified when your training ends with only two additional lines of code
https://github.com/huggingface/safetensors # Simple, safe way to store and distribute tensors
https://github.com/huggingface/text-embeddings-inference # A blazing fast inference solution for text embeddings models
https://github.com/huggingface/swift-coreml-diffusers # Swift app demonstrating Core ML Stable Diffusion
https://github.com/huggingface/optimum # üöÄ Accelerate training and inference of ü§ó Transformers and ü§ó Diffusers with easy to use hardware optimization tools
https://github.com/huggingface/blog # Public repo for HF blog posts
https://github.com/huggingface/setfit # Efficient few-shot learning with Sentence Transformers
https://github.com/huggingface/course # The Hugging Face course on Transformers
https://github.com/huggingface/awesome-papers # Papers & presentation materials from Hugging Face's internal science day
https://github.com/huggingface/huggingface_hub # The official Python client for the Huggingface Hub.
https://github.com/huggingface/evaluate # ü§ó Evaluate: A library for easily evaluating machine learning models and datasets.
https://github.com/huggingface/datatrove # Freeing data processing from scripting madness by providing a set of platform-agnostic customizable pipeline processing blocks.
https://github.com/huggingface/transfer-learning-conv-ai # ü¶Ñ State-of-the-Art Conversational AI with Transfer Learning
https://github.com/huggingface/cookbook # Open-source AI cookbook
https://github.com/huggingface/swift-coreml-transformers # Swift Core ML 3 implementations of GPT-2, DistilGPT-2, BERT, and DistilBERT for Question answering. Other Transformers coming soon!
https://github.com/huggingface/pytorch-openai-transformer-lm # üê•A PyTorch implementation of OpenAI's finetuned transformer language model with a script to import the weights pre-trained by OpenAI
https://github.com/huggingface/huggingface.js # Utilities to use the Hugging Face Hub API
https://github.com/huggingface/gsplat.js # JavaScript Gaussian Splatting library.
https://github.com/huggingface/mongoku # üî•The Web-scale GUI for MongoDB
https://github.com/huggingface/llm-vscode # LLM powered development for VSCode
https://github.com/huggingface/hmtl # üåäHMTL: Hierarchical Multi-Task Learning - A State-of-the-Art neural network model for several NLP tasks based on PyTorch and AllenNLP
https://github.com/huggingface/nanotron # Minimalistic large language model 3D-parallelism training
https://github.com/huggingface/pytorch-pretrained-biggan # ü¶ãA PyTorch implementation of BigGAN with pretrained weights and conversion scripts.
https://github.com/huggingface/torchmoji # üòáA pyTorch implementation of the DeepMoji model: state-of-the-art deep learning model for analyzing sentiment, emotion, sarcasm etc
https://github.com/huggingface/optimum-nvidia #
https://github.com/huggingface/awesome-huggingface # ü§ó A list of wonderful open-source projects & applications integrated with Hugging Face libraries.
https://github.com/huggingface/chat-macos # Making the community's best AI chat models available to everyone.
https://github.com/huggingface/optimum-quanto # A pytorch quantization backend for optimum
https://github.com/huggingface/llm.nvim # LLM powered development for Neovim
https://github.com/huggingface/naacl_transfer_learning_tutorial # Repository of code for the tutorial on Transfer Learning in NLP held at NAACL 2019 in Minneapolis, MN, USA
https://github.com/huggingface/lighteval # Lighteval is your all-in-one toolkit for evaluating LLMs across multiple backends
https://github.com/huggingface/dataset-viewer # Backend that powers the dataset viewer on Hugging Face dataset pages through a public API.
https://github.com/huggingface/swift-transformers # Swift Package to implement a transformers-like API in Swift
https://github.com/huggingface/exporters # Export Hugging Face models to Core ML and TensorFlow Lite
https://github.com/huggingface/llm-ls # LSP server leveraging LLMs for code completion (and more?)
https://github.com/huggingface/ratchet # A cross-platform browser ML framework.
https://github.com/huggingface/transformers-bloom-inference # Fast Inference Solutions for BLOOM
https://github.com/huggingface/pytorch_block_sparse # Fast Block Sparse Matrices for Pytorch
https://github.com/huggingface/node-question-answering # Fast and production-ready question answering in Node.js
https://github.com/huggingface/swift-chat # Mac app to demonstrate swift-transformers
https://github.com/huggingface/large_language_model_training_playbook # An open collection of implementation tips, tricks and resources for training large language models
https://github.com/huggingface/llm_training_handbook # An open collection of methodologies to help with successful training of large language models.
https://github.com/huggingface/text-clustering # Easily embed, cluster and semantically label text datasets
https://github.com/huggingface/cosmopedia #
https://github.com/huggingface/community-events # Place where folks can contribute to ü§ó community events
https://github.com/huggingface/nn_pruning # Prune a model while finetuning or training.
https://github.com/huggingface/tflite-android-transformers # DistilBERT / GPT-2 for on-device inference thanks to TensorFlow Lite with Android demo apps
https://github.com/huggingface/optimum-intel # ü§ó Optimum Intel: Accelerate inference with Intel optimization tools
https://github.com/huggingface/controlnet_aux #
https://github.com/huggingface/transformers.js-examples # A collection of ü§ó Transformers.js demos and example applications
https://github.com/huggingface/speechbox #
https://github.com/huggingface/100-times-faster-nlp # üöÄ100 Times Faster Natural Language Processing in Python - iPython notebook
https://github.com/huggingface/huggingface-llama-recipes #
https://github.com/huggingface/education-toolkit # Educational materials for universities
https://github.com/huggingface/local-gemma # Gemma 2 optimized for your local machine.
https://github.com/huggingface/open-muse # Open reproduction of MUSE for fast text2image generation.
https://github.com/huggingface/audio-transformers-course # The Hugging Face Course on Transformers for Audio
https://github.com/huggingface/unity-api #
https://github.com/huggingface/datablations # Scaling Data-Constrained Language Models
https://github.com/huggingface/hf_transfer #
https://github.com/huggingface/dataspeech #
https://github.com/huggingface/hub-docs # Docs of the Hugging Face Hub
https://github.com/huggingface/diarizers #
https://github.com/huggingface/optimum-benchmark # üèãÔ∏è A unified multi-backend utility for benchmarking Transformers, Timm, PEFT, Diffusers and Sentence-Transformers with full support of Optimum's hardware optimizations & quantization schemes.
https://github.com/huggingface/llm-swarm # Manage scalable open LLM inference endpoints in Slurm clusters
https://github.com/huggingface/instruction-tuned-sd # Code for instruction-tuning Stable Diffusion.
https://github.com/huggingface/sam2-studio #
https://github.com/huggingface/data-is-better-together # Let's build better datasets, together!
https://github.com/huggingface/optimum-neuron # Easy, fast and very cheap training and inference on AWS Trainium and Inferentia chips.
https://github.com/huggingface/simulate # üé¢ Creating and sharing simulation environments for embodied and synthetic data research
https://github.com/huggingface/obelics # Code used for the creation of OBELICS, an open, massive and curated collection of interleaved image-text web documents, containing 141M documents, 115B text tokens and 353M images.
https://github.com/huggingface/diffusion-fast # Faster generation with text-to-image diffusion models.
https://github.com/huggingface/olm-datasets # Pipeline for pulling and processing online language model pretraining data from the web
https://github.com/huggingface/api-inference-community #
https://github.com/huggingface/jat # General multi-task deep RL Agent
https://github.com/huggingface/chug # Minimal sharded dataset loaders, decoders, and utils for multi-modal document, image, and text datasets.
https://github.com/huggingface/workshops # Materials for workshops on the Hugging Face ecosystem
https://github.com/huggingface/coreml-examples # Swift Core ML Examples
https://github.com/huggingface/optimum-habana # Easy and lightning fast training of ü§ó Transformers on Habana Gaudi processor (HPU)
https://github.com/huggingface/sharp-transformers # A Unity plugin for using Transformers models in Unity.
https://github.com/huggingface/hf-hub # Rust client for the huggingface hub aiming for minimal subset of features over `huggingface-hub` python package
https://github.com/huggingface/frp # FRP Fork
https://github.com/huggingface/google-cloud-containers # Hugging Face Deep Learning Containers (DLCs) for Google Cloud
https://github.com/huggingface/competitions #
https://github.com/huggingface/ml-for-3d-course #
https://github.com/huggingface/olm-training # Repo for training MLMs, CLMs, or T5-type models on the OLM pretraining data, but it should work with any hugging face text dataset.
https://github.com/huggingface/fuego # [WIP] A üî• interface for running code in the cloud
https://github.com/huggingface/tune #
https://github.com/huggingface/doc-builder # The package used to build the documentation of our Hugging Face repos
https://github.com/huggingface/optimum-graphcore # Blazing fast training of ü§ó Transformers on Graphcore IPUs
https://github.com/huggingface/block_movement_pruning # Block Sparse movement pruning
https://github.com/huggingface/huggingface_sb3 # Additional code for Stable-baselines3 to load and upload models from the Hub.
https://github.com/huggingface/amused #
https://github.com/huggingface/visual-blocks-custom-components # Custom Hugging Face Nodes for Google Visual Blocks for ML
https://github.com/huggingface/paper-style-guide #
https://github.com/huggingface/hfapi # Simple Python client for the Hugging Face Inference API
https://github.com/huggingface/data-measurements-tool # Developing tools to automatically analyze datasets
https://github.com/huggingface/disaggregators # ü§ó Disaggregators: Curated data labelers for in-depth analysis.
https://github.com/huggingface/making-games-with-ai-course # This repository contains the ML For Games Course
https://github.com/huggingface/llm-intellij # LLM powered development for IntelliJ
https://github.com/huggingface/optimum-tpu # Google TPU optimizations for transformers models
https://github.com/huggingface/that_is_good_data #
https://github.com/huggingface/bloom-jax-inference #
https://github.com/huggingface/personas # Datasets for Deep learning Personas
https://github.com/huggingface/m4-logs # M4 experiment logbook
https://github.com/huggingface/open_asr_leaderboard #
https://github.com/huggingface/discord-bots #
https://github.com/huggingface/optimum-amd # AMD related optimizations for transformer models
https://github.com/huggingface/zapier # Hugging Face's Zapier Integration ü§ó‚ö°Ô∏è
https://github.com/huggingface/gym-pusht # A gym environment for PushT
https://github.com/huggingface/gym-aloha # A gym environment for ALOHA
https://github.com/huggingface/adversarialnlp # A generic library for crafting adversarial NLP examples - WIP
https://github.com/huggingface/transformers_bloom_parallel # Techniques used to run BLOOM at inference in parallel
https://github.com/huggingface/huggingface-inference-toolkit # Hugging Face Inference Toolkit used to serve transformers, sentence-transformers, and diffusers models.
https://github.com/huggingface/neuralcoref-viz # ‚ú® Web interface for NeuralCoref coreference resolution
https://github.com/huggingface/gym-xarm # A gym environment for xArm
https://github.com/huggingface/rlhf-interface #
https://github.com/huggingface/rasa_hmtl # RASA wrapper for HMTL: Hierarchical Multi-Task Learning
https://github.com/huggingface/finevideo #
https://github.com/huggingface/optimum-furiosa # Accelerated inference of ü§ó models using FuriosaAI NPU chips.
https://github.com/huggingface/hf-endpoints-emulator # Local emulator for Hugging Face Inference Endpoints customer handlers
https://github.com/huggingface/distill-bloom-deepspeed # Teacher - student distillation using DeepSpeed
https://github.com/huggingface/spm_precompiled # Highly specialized crate to parse and use `google/sentencepiece` 's precompiled_charsmap in `tokenizers`
https://github.com/huggingface/gaia # Hugging Face and Pyserini interoperability
https://github.com/huggingface/semver-release-action #
https://github.com/huggingface/doc-build #
https://github.com/huggingface/snapchat-lens-api # Type definitions for Snapchat Lenses scripting
https://github.com/huggingface/leaderboards #
https://github.com/huggingface/ethics-scripts #
https://github.com/huggingface/peft-pytorch-conference # Code for the examples presented in the talk "Training a Llama in your backyard: fine-tuning very large models on consumer hardware" given at PyTorch Conference 2023
https://github.com/huggingface/hf_benchmarks # A starter kit for evaluating benchmarks on the ü§ó Hub
https://github.com/huggingface/unity-webgl-template-for-hugging-face-spaces # Unity WebGL template for Hugging Face Spaces
https://github.com/huggingface/model-evaluator # Evaluate Transformers from the Hub üî•
https://github.com/huggingface/pixparse # Pixel Parsing. A reproduction of OCR-free end-to-end document understanding models with open data
https://github.com/huggingface/candle-paged-attention #
https://github.com/huggingface/pyo3-special-method-derive # Automatically derive Python dunder methods for your Rust code
https://github.com/huggingface/candle-cublaslt #
https://github.com/huggingface/efficient_scripts #
https://github.com/huggingface/roots-search-tool # Scripts supporting the development and serving the Roots Search Tool - https://hf.co/spaces/bigscience-data/roots-search
https://github.com/huggingface/docmatix # A huge dataset for Document Visual Question Answering
https://github.com/huggingface/hf-endpoints-documentation #
https://github.com/huggingface/khipu_workshop #
https://github.com/huggingface/energystarai # A repository for the AI Energy Star Project, aiming to establish energy efficiency ratings for AI models
https://github.com/huggingface/ethics-education # AI Ethics educational material ü§ó
https://github.com/huggingface/autogptq-index # A GitHub Pages hosting AutoGPTQ wheels
https://github.com/huggingface/neuralcoref-models # ‚ú® Models for the NeuralCoref coreference resolution module
https://github.com/huggingface/candle-rotary #
https://github.com/huggingface/candle-flash-attn-v1 #
https://github.com/huggingface/helm-common # Common chart for our helm charts
https://github.com/huggingface/helm-publish-action # Github Action to simplify Helm Chart publish into a registry
https://github.com/huggingface/hf-rocm-benchmark # A reproducible benchmark of Text Generation Inference and Transformers as of April 2024 on AMD Instinct MI250 and MI300
https://github.com/huggingface/collaborative-training-auth # Collaborative Hub Training Authentication API server-side machinery
https://github.com/huggingface/huggy # Huggy is a Unity ML-Agents environment showcasing a dog mastering stick-catching through deep reinforcement learning.
https://github.com/huggingface/ml-agents-training-executables # This repo contains the Unity ML-Agents environments' executables for Windows, Mac and Linux
https://github.com/huggingface/candle-layer-norm #
https://github.com/huggingface/tailscale-action # Github action to connect to tailscale
https://github.com/huggingface/autotrain-advanced-api #
https://github.com/huggingface/text-generation-inference-nix #
https://github.com/huggingface/gguf-jinja-analysis #
https://github.com/huggingface/unity-mlagents-loadfromhub-assets # Unity scripts and UI for easily loading models from the Hugging Face Hub
https://github.com/huggingface/huggingface-sagemaker-snowflake-example #
https://github.com/huggingface/rl-model-card-template # Model card template
https://github.com/huggingface/candle-silu #
https://github.com/huggingface/snowball-target # Snowball Target is a Unity ML-Agents environment where you need to train Julien the Bear to shoot snowballs onto spawning targets
https://github.com/huggingface/bench_cluster #
https://github.com/huggingface/autotrain-example-datasets #
https://github.com/huggingface/chat-ui-android #
https://github.com/huggingface/test_gh_secret # dummy repo testing github workflow secrets
https://github.com/huggingface/temp-tailscale-action #
https://github.com/huggingface/hf-workflows #
https://github.com/huggingface/ms-build-mi300 #
https://github.com/huggingface/action-check-commits # A simple GitHub action that checks the list of commits in a pull-request.
https://github.com/huggingface/hub-js-utils #
https://github.com/huggingface/distribution-v2 #
https://github.com/huggingface/dedupe_estimator # Chunk Dedupe Estimation
https://github.com/huggingface/test-actions #
https://github.com/huggingface/llm-academy # LLM Academy
